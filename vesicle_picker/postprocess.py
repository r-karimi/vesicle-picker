from vesicle_picker import helpers
import numpy as np
import copy
import cv2
import configparser
import pandas as pd


def find_mask_intensity(input_mask, preprocessed_micrograph):

    """
    Takes a single input mask and computes the mean pixel intensity
    in the region bounded by the mask.

    Arguments:
    input_mask (dictionary): A single mask, as generated by segmentation
    of a micrograph by generate_masks().
    preprocessed_micrograph (np.ndarray): A downsampled and blurred micrograph
    used in semgmentation, in the form of a 2D numpy array.

    Outputs:
    mask (dictionary): The input mask with a new key added ('intensity')
    along with the mean pixel intensity in the region bouned by the mask.
    """

    # Make a copy of the input mask
    mask = copy.deepcopy(input_mask)

    # Find the average pixel value within the mask and assign it to a new key
    mask['intensity'] = np.mean(preprocessed_micrograph[mask['segmentation']])

    # Return the mask
    return mask


def find_contour(input_mask):

    """
    Takes a single input mask and finds the contour/edge
    of the object contained within.

    Arguments:
    input_mask (dictionary): A single mask, as generated by segmentation
    of a micrograph by generate_masks().

    Outputs:
    mask (dictionary): The input mask with two new keys added
    ('contours' and 'edge_mask') containing the openCV contour object
    and a new segmentation array of just edges, respectively.
    """

    # Make a copy of the input mask
    mask = copy.deepcopy(input_mask)

    # Isolate the 2D image array from the mask dictionary
    mask_array = mask['segmentation']

    # Find the contours with openCV
    contours, _ = cv2.findContours(mask_array.astype(np.uint8)*255,
                                   cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    # Create a blank image with the same size and type as binary_image
    contour_image = (
        np.ascontiguousarray(
            np.zeros_like(mask_array.astype(np.uint8), dtype=np.uint8)
        )
    )

    # Draw the contour onto a new 2D array
    cv2.drawContours(contour_image, contours, -1, (255, 255, 255), 1)

    # Assign the contour object to a new slot in the masks dictionary
    mask['edge'] = contour_image.astype(bool)
    mask['contours'] = contours

    if len(mask['contours']) == 0:
        return None

    # Return the new mask with the elements added
    return mask


def find_roundness(input_contoured_mask):

    """
    Takes a single input mask with a countour already calculated
    and computes the roundness of the object contained within.

    Arguments:
    input_contoured_mask (dictionary): A single mask that has had its
    contours computed already with find_contours().

    Outputs:
    contoured_mask (dictionary): The input mask with a new key added
    ('roundness') containing the value of the ratio 4*pi*area/(perimeter**2),
    which is 1 for a perfect circle and smaller otherwise.
    """

    # Make a copy of the input mask
    contoured_mask = copy.deepcopy(input_contoured_mask)

    # Find the perimeter of the mask
    perimeter = cv2.arcLength(contoured_mask['contours'][0], closed=True)

    if perimeter == 0:
        contoured_mask['roundness'] = 0
        return contoured_mask

    # Compute the roundness directly using the area key of the mask
    # and add it as a new key:value pair
    contoured_mask['roundness'] = (
        (4*np.pi*contoured_mask['area'])/(perimeter**2)
    )

    # Return the new mask with the elements added
    return contoured_mask


def fit_ellipse(input_contoured_mask):

    """
    Takes a single input mask and finds the contour/edge
    of the object contained within.

    Arguments:
    input_contoured_mask (dictionary): A single mask that has had
    its contours computed already with find_contours().

    Outputs:
    contoured_mask (dictionary): The input mask with four new keys added:
    ('semi_major', 'semi_minor', 'average_radius' and 'radii_ratio')
    containing the shortest radius, longest radius,
    average radius, and the ratio of the shortest to longest
    radius of the ellipse, respectively.
    """

    # Make a copy of the input mask
    contoured_mask = copy.deepcopy(input_contoured_mask)

    # Fit an ellipse to the computed contour of the mask
    ellipse = cv2.fitEllipse(contoured_mask['contours'][0])

    # Extract the semi_major_axis and semi_minor_axis of the ellipse
    _, axes, _ = ellipse
    semi_minor_axis, semi_major_axis = axes

    # Compute the average radius as (ab)**1/2,
    # the radius of a circle that would give the same area
    average_radius = np.sqrt(semi_major_axis*semi_minor_axis)

    # Compute the ratio of the semi-major and semi-minor axes
    # as an alternate measure of roundness
    radii_ratio = semi_minor_axis/semi_major_axis

    # Return these parameters as key:value pairs on the input mask
    contoured_mask['semi_minor'] = semi_minor_axis/2
    contoured_mask['semi_major'] = semi_major_axis/2
    contoured_mask['average_radius'] = average_radius/2
    contoured_mask['radii_ratio'] = radii_ratio

    # Return the new mask with the elements added
    return contoured_mask


def postprocess_masks(input_masks, postprocess_list,
                      preprocessed_micrograph=None):

    """
    Takes a list of untransformed masks and applies various postprocessing
    functions to them in the order specificed in postprocess_list.

    Arguments:
    input_masks (list): Masks found by segmentation of a
    micrograph with generate_masks().
    postprocess_list (list): The postprocessing functions to
    be applied to the masks. Note: contours should be found
    before computing roundness or fitting an ellipse.
    preprocessed_micrograph (np.ndarray): The preprocessed micrograph
    used to generate the masks, needed for find_mask_intensity()

    Outputs:
    postprocessed_masks (list): List of mask dictionaries (masks)
    with additional keys added from postprocessing steps.
    """

    # Make a copy of input_masks to not mess with the original
    masks = copy.deepcopy(input_masks)

    # For each function in the list of postprocessing functions
    for function in postprocess_list:
        # If the function is find_mask_intensity,
        # pass along preprocessed_micrograph.
        if function == find_mask_intensity:
            masks = [function(mask, preprocessed_micrograph) for mask in masks]
        else:
            # Otherwise, just apply the function across the list of masks
            masks = [function(mask) for mask in masks]

    # Return the transformed list of masks
    return masks


def apply_filters(postprocessed_masks, filters_path):

    """
    Takes a list of transformed masks and filters them based
    on the parameters specified in filters_path.

    Arguments:
    postprocessed_masks (list): List of mask dictionaries (masks)
    with additional keys added from postprocessing steps.
    filters_path (str): Path to an INI file in the working directory
    specifying the minimum and maximum values of various
    postprocessing parameters to be accepted.

    Outputs:
    filtered_masks (list): List of masks that passed all postprocessing
    filters specified in the INI file at filters_path.
    """

    config = configparser.ConfigParser()
    config.read(filters_path)

    # Make a copy of postprocessed masks
    filtered_masks = copy.deepcopy(postprocessed_masks)

    # For each section heading in the config file
    for filter in config.sections():
        if filter in ('csparc_input', 'input', 'general', 'output'):
            continue
        else:
            # Set filtered masks equal to a filtered mask list
            # with list comprehension
            filtered_masks = [
                mask for mask in filtered_masks
                if mask[filter] >= float(config.get(filter, 'min'))
                and mask[filter] <= float(config.get(filter, 'max'))
            ]

    # Return the filtered set of masks
    return filtered_masks


def extract_statistics(postprocessed_masks, filters_path):

    """
    Takes a list of transformed masks and filters them
    based on the parameters specified in filters_path.

    Arguments:
    postprocessed_masks (list): List of mask dictionaries (masks)
    with additional keys added from postprocessing steps.
    filters_path (str): Path to an INI file in the working directory
    specifying the minimum and maximum values of various
    postprocessing parameters to be accepted.

    Outputs:
    unfiltered_stats (pd.Dataframe): Pandas dataframe with postprocessing
    parameters specified in the INI file at filters_path as the columns
    and the values for each mask as rows without the filters applied.
    filtered_stats (pd.Dataframe): Pandas dataframe with postprocessing
    parameters specified in the INI file at filters_path as the columns
    and the values for each mask as rows with the filters applied.
    """

    config = configparser.ConfigParser()
    config.read(filters_path)

    # Instead of filtering off masks that don't meet the criteria,
    # use that to generate a filtered and unfiltered Pandas dataset
    unfiltered_masks = copy.deepcopy(postprocessed_masks)
    filtered_masks = apply_filters(copy.deepcopy(unfiltered_masks),
                                   filters_path)

    # Extract stats from unfiltered dataset
    unfiltered_stats = {
        filter: [
            unfiltered_mask[filter] for unfiltered_mask in unfiltered_masks
        ]
        for filter in config.sections()
    }

    # Turn it into a pandas dataset
    unfiltered_stats = pd.DataFrame(unfiltered_stats)

    # Extract stats from filtered dataset
    filtered_stats = {
        filter: [
            filtered_mask[filter] for filtered_mask in filtered_masks
        ]
        for filter in config.sections()
    }

    # Turn it into a pandas dataset
    filtered_stats = pd.DataFrame(filtered_stats)

    # Return unfiltered stats
    return unfiltered_stats, filtered_stats


def dilate_masks(masks, dilation, psize, downsample):

    """
    Takes a list of masks and dilates each one by an approximate
    radial distance in Angstrom.

    Arguments:
    masks (list): List of mask dictionaries (masks) with additional
    keys added from postprocessing steps.
    dilation (int): The dilation distance in Angstrom.
    psize (float): The pixel size of the original micrograph (Angstrom/pixel).
    downsample (int): The downsampling factor applied when generating masks.
    """

    for mask in masks:
        mask['segmentation'] = cv2.dilate(
            mask['segmentation'].astype(np.uint8),
            np.ones((3, 3), np.uint8),
            iterations=int(np.round(dilation / (psize * downsample)))
        ).astype(bool)
        mask['edge'] = find_contour(mask)['edge']
    return masks


def erode_masks(masks, erosion, psize, downsample):

    """
    Takes a list of masks and erodes each one by an approximate
    radial distance in Angstrom.

    Arguments:
    masks (list): List of mask dictionaries (masks) with additional
    keys added from postprocessing steps.
    erosion (int): The erosion distance in Angstrom.
    psize (float): The pixel size of the original micrographs (Angstrom/pixel).
    downsample (int): The downsampling factor applied when generating masks.
    """

    for mask in masks:
        mask['segmentation'] = cv2.erode(
            mask['segmentation'].astype(np.uint8),
            np.ones((3, 3), np.uint8),
            iterations=int(np.round(erosion / (psize * downsample)))
        ).astype(bool)
        mask['edge'] = find_contour(mask)['edge']
    return masks


def generate_picks(masks, psize, downsample, box_size, mode='edge'):

    """
    Takes masks found by segment-anything and returns evenly spaced
    particle picks along the edge or the surface of the object masks.

    Arguments:
    masks (list): Masks found by segmentation of a micrograph,
    with or without postprocessing.
    downsample (int): The downsampling factor applied when generating masks.
    psize (float): The pixel size of the original micrograph (Angstrom/pixel).
    box_size (int): The spacing used to make a grid of picks in
    the micrograph, in Angstrom. A larger number represents sparcer picks.
    mode (str): Whether to return edge ("edge") or surface picks ("surface").

    Outputs:
    pick_indices (list): A list of numpy arrays containing the
    0th axis and 1st axis indices of particle pick locations,
    respectively, upsampled to map back onto the full-resolution micrograph.
    """

    # Generate picks based on whether user wants surfaces, edges, or both
    if mode == "edge":
        pick_mask = helpers.sum_masks(masks, 'edge')
    elif mode == "surface":
        pick_mask = helpers.sum_masks(masks, 'segmentation')
    else:
        raise Exception("Please input a valid picking mode.")

    # Convert the given box size in Angstrom
    # to the closest compatible box size in pixels.
    box_size = int(np.round(box_size/(psize*downsample)))

    # Zero pad the image
    h_org = pick_mask.shape[0]
    w_org = pick_mask.shape[1]
    h_pad = int(np.ceil(h_org/box_size)*box_size - h_org)
    w_pad = int(np.ceil(w_org/box_size)*box_size - w_org)
    pick_mask_pad = np.pad(pick_mask, ((0,h_pad),(0,w_pad)), "constant")

    # Split the micrograph into evenly spaced grids assuming square micrograph
    split_pick_mask = helpers.blockshaped(pick_mask_pad, box_size, box_size)

    # In each patch, if the sum of the mask is greater
    # than zero (i.e. if there is an edge)
    # select the pick closest to the center by setting all
    # other values in the patch to zero
    for i in range(split_pick_mask.shape[0]):
        this_patch = np.copy(split_pick_mask[i, :, :])
        if np.sum(this_patch) > 0:
            indices = np.argwhere(this_patch)
            distances = np.sum((indices - box_size / 2) ** 2, axis=1)
            best_indices = indices[np.argmin(distances)]
            this_patch = np.zeros(this_patch.shape)
            this_patch[best_indices[0], best_indices[1]] = 1
            split_pick_mask[i, :, :] = this_patch

    # Undo the split
    merged_pick_mask_pad = helpers.unblockshaped(
        split_pick_mask,
        pick_mask_pad.shape[0],
        pick_mask_pad.shape[1]
    )

    # Undo the pad
    merged_pick_mask = merged_pick_mask_pad[0:h_org, 0:w_org]

    # Generate the pick indices
    pick_indices = np.where(merged_pick_mask == 1)

    # Map the grid pick indices back to the full-res image
    pick_indices = (downsample*pick_indices[0], downsample*pick_indices[1])

    return pick_indices
